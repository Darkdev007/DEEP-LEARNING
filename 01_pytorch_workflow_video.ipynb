{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1ABdpWm6NaD"
      },
      "outputs": [],
      "source": [
        "#PyTorch Workflow\n",
        "what_we_are_covering = {1: \"data (prepare and load)\",\n",
        "                        2: \"build model\",\n",
        "                        3: \"fitting the model to data(training)\",\n",
        "                        4: \"making predictions and evaluating a model (inference)\",\n",
        "                        5: \"saving and loading a model\",\n",
        "                        6: \"putting it all together\"}\n",
        "\n",
        "what_we_are_covering"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn # contains all of pytorch's building block for neural network\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "torch.__version__"
      ],
      "metadata": {
        "id": "vCLJrCsN7llv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data (preparing and loading)\n",
        "\n",
        "Data can be almost anything in machine learning.\n",
        "\n",
        "* Excel spreadhseet\n",
        "* Images of any kind\n",
        "* Audio\n",
        "* DNA\n",
        "* Text\n",
        "\n",
        "Machine learning is a game of two parts:\n",
        "1. Get data into a numerical representation\n",
        "2. Build a mode to learn pattenrs in that numerical representation\n",
        "\n",
        "To represent this lets create some *known* data using the linear regression formula.\n",
        "\n",
        "We will use a linear regression formula to make a straight line with *known* parameters"
      ],
      "metadata": {
        "id": "ggOV6NTD8YJN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#create known parameters\n",
        "weight = 0.7\n",
        "bias = 0.3\n",
        "\n",
        "# Create\n",
        "start = 0\n",
        "end = 1\n",
        "step = 0.02\n",
        "X = torch.arange(start, end, step).unsqueeze(dim=1)\n",
        "y = weight * X + bias\n",
        "\n",
        "X[:10], y[:10]"
      ],
      "metadata": {
        "id": "qq0JyCM6-e8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X), len(y)"
      ],
      "metadata": {
        "id": "Z_sT06rHBQcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Splitting data into training and test sets\n"
      ],
      "metadata": {
        "id": "oL8236A9-9Xk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_split = int(0.8 * len(X))\n",
        "X_train, y_train = X[:train_split], y[:train_split]\n",
        "X_test, y_test = X[train_split:], y[train_split:]\n",
        "\n",
        "len(X_train), len(y_train), len(X_test), len(y_test)"
      ],
      "metadata": {
        "id": "m6Z0WUt3BemN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#To better visualie your data"
      ],
      "metadata": {
        "id": "OPoGlW2HCBLP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_predictions(train_data = X_train,\n",
        "                     train_labels = y_train,\n",
        "                     test_data = X_test,\n",
        "                     test_labels = y_test,\n",
        "                     predictions = None):\n",
        "  plt.figure(figsize=(10, 7 ))\n",
        "  plt.scatter(train_data, train_labels, c=\"b\", s=4, label=\"Training data\")\n",
        "  plt.scatter(test_data, test_labels, c=\"g\", s=4, label=\"Test data\")\n",
        "\n",
        "  if predictions is not None:\n",
        "    plt.scatter(test_data, predictions, c=\"r\", s=4, label=\"Predictions\")\n",
        "\n",
        "    plt.legend(prop={\"size\" : 14});"
      ],
      "metadata": {
        "id": "1SdmFdJ6CQs3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_predictions()"
      ],
      "metadata": {
        "id": "CJXeo0RcE3U4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#building first model\n"
      ],
      "metadata": {
        "id": "04ATMHq5FaIq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "#Create linear regression model class\n",
        "class LinearRegressionModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.weights = nn.Parameter(torch.randn(1, requires_grad=True))\n",
        "    self.bias = nn.Parameter(torch.randn(1, requires_grad=True))\n",
        "\n",
        "    #Forward method to define the compuation in the model\n",
        "  def forward(self, x:torch.tensor) -> torch.tensor:\n",
        "    return self.weights * x + self.bias #this is the linear regression formula"
      ],
      "metadata": {
        "id": "-ZAdTpkaZwNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PyTorch model building essentials\n",
        "\n",
        "* torch.nn - contains all of the buildings for computational graphs (a neural network can be considered a computational graph)\n",
        "* torch.nn.Parameter - what parameters should our model try and learn, often a pytorch layer from torch.nn will set this for use\n",
        "* torch.nn.Module - The base class for all neural network modules, if you subclass it, you should overwrite forward()\n",
        "* torch.optim - this is where the optimiers in Pytorch live, they will help with gradient DeserializationStorageContext\n",
        "* def forward () - All nn.Module Subclasses require you to overwrite the forward() method"
      ],
      "metadata": {
        "id": "reX6h0So8ii9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Checking the contents of our pytorch model using '.parameters()'"
      ],
      "metadata": {
        "id": "7uRdQ-Yb86JP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a random seed\n",
        "torch.manual_seed(42)\n",
        "\n",
        "#create an instance of the model\n",
        "model_0 = LinearRegressionModel()\n",
        "\n",
        "#check out the parameters\n",
        "list(model_0.parameters())"
      ],
      "metadata": {
        "id": "L6LdCiJFAG5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List named Parameters\n",
        "model_0.state_dict()"
      ],
      "metadata": {
        "id": "rQAA4qnCAfbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test, y_test"
      ],
      "metadata": {
        "id": "D9nXubvjFxaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model_0(X_test)\n",
        "y_pred"
      ],
      "metadata": {
        "id": "HdQusFrVIhpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Making predictions with inference mode"
      ],
      "metadata": {
        "id": "Fi_ZwomNJUCe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with model\n",
        "#Inference mode turns off the gradient cause we dont need to keep track\n",
        "#predictions will be a lot faster cause things are being kept track of\n",
        "\n",
        "with torch.inference_mode():\n",
        "  y_preds = model_0(X_test)\n",
        "\n",
        "y_preds\n",
        "\n",
        "# You can do something similar with torch.no_grad\n",
        "with torch.no_grad():\n",
        "  y_preds = model_0(X_test)\n",
        "\n",
        "y_preds"
      ],
      "metadata": {
        "id": "_1Dz6weHClLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_predictions(predictions=y_preds)"
      ],
      "metadata": {
        "id": "DIl8TaagJa45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train model\n",
        "\n",
        "A way to measure how poorly your predicitons are is to use a loss function\n",
        "\n",
        "The smaller the better (Mean absolute Error)\n",
        "Things we need to train\n",
        "* loss function : A function to measure how wrong your models predictions are\n",
        "* optimizer : takes into account the loss of a model and adjusts the model's parameters.\n",
        "\n",
        "And for pytorch we need:\n",
        "* A training loop\n",
        "* A testing loop"
      ],
      "metadata": {
        "id": "pf3hCQdrOIoL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup a loss function\n",
        "loss_fn = nn.L1Loss()\n",
        "\n",
        "#setup an optimier\n",
        "optimizer = torch.optim.SGD(params = model_0.parameters(),\n",
        "                           lr = 0.01) #learning rate, the smaller the learning rate the smaller the change in parameter"
      ],
      "metadata": {
        "id": "v2sP-h3kOhdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Builing a training loop and a testing loop in Pytorch\n",
        "\n",
        "A couple of things we need in a training loop:\n",
        "0. Loop through the data\n",
        "1. Forward pass (this involves data moving thorugh our model's forward() functions)to make predicitons on data\n",
        "2. Calculate the loss (compare forward pass predicitions to ground truth labels)\n",
        "3. Optimizer zero grad\n",
        "4. Loss backward - move backwards through the network to calculate the gradients of each of the parameters of our model with respect to the loss (** back propagation**)\n",
        "5. Optimier step - use our project parameters to try and improve the loss (**gradient descent**)\n",
        "\n"
      ],
      "metadata": {
        "id": "2jXvwLrT1Xfp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#An epoch is one loop through the data\n",
        "epochs = 100\n",
        "\n",
        "#Track different values\n",
        "epoch_count = []\n",
        "lose_values = []\n",
        "test_loss_values = []\n",
        "#0, Loop through the data\n",
        "for epoch in range(epochs):\n",
        "  # Set the model to training mode\n",
        "  model_0.train() # train mode in pyTorch sets all parameters that require gradients to require gradient\n",
        "\n",
        "\n",
        "  #1. Forward pass\n",
        "  y_pred = model_0(X_train)\n",
        "\n",
        "  #2. Calculate the loss\n",
        "  loss = loss_fn(y_pred, y_train)\n",
        "\n",
        "\n",
        "  #3. Optimizer zero grad\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  #4. Perform backpropagation on the loss with respect to the parameters of the model\n",
        "  loss.backward()\n",
        "\n",
        "  #5. Step the optimizer (perform gradient descent)\n",
        "  optimizer.step()\n",
        "\n",
        "  ### Testing\n",
        "  model_0.eval() # turns off different seetings in the model not needed for evaluation/testing (dropout laters)\n",
        "  with torch.inference_mode():\n",
        "    #1. Do the forward pass\n",
        "    test_pred = model_0(X_test)\n",
        "\n",
        "    #2. Calculate the loss\n",
        "    test_loss = loss_fn(test_pred, y_test)\n",
        "\n",
        "  #print whats happening\n",
        "  if epoch % 10 == 0 :\n",
        "    print(f\"Epoch: {epoch} | Loss: {loss} | Test loss : {test_loss}\")\n",
        "    print(model_0.state_dict())\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wf_T-C3h19Iv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0.state_dict()"
      ],
      "metadata": {
        "id": "c9VT70nLBf5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0.state_dict()"
      ],
      "metadata": {
        "id": "VCc-GRc_BiRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Saving a model in PyTorch\n",
        "There are three main methods you should know about for saving and loading models in PyTorch.\n",
        "\n",
        "1. torch.save() - allows you save a PyTorch object in Python's pickle format\n",
        "2. torch.load() - allows you load a saved PyTorch object\n",
        "3. torch.nn.Module.load_state_dict() - this allows to load a models saved from dictionary\n"
      ],
      "metadata": {
        "id": "k_gKlscaBre6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "nEKuj3l0Lynx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Saving our PyTorch model\n",
        "from pathlib import Path\n",
        "\n",
        "# 1. Create models directory\n",
        "MODEL_PATH = Path(\"models\")\n",
        "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 2. Create model save path\n",
        "MODEL_NAME = \"1_pytorch_workflow_model.pth\"\n",
        "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
        "\n",
        "MODEL_SAVE_PATH\n",
        "\n",
        "# 3. Save the model state dict\n",
        "print(f'Saving model to : {MODEL_SAVE_PATH}')\n",
        "torch.save(obj=model_0.state_dict(), f=MODEL_SAVE_PATH)"
      ],
      "metadata": {
        "id": "V2G4ALfBLwfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Loading a PyTorch model\n",
        "loaded_model_0 = LinearRegressionModel()"
      ],
      "metadata": {
        "id": "w6Am9JJqOOZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model_0.state_dict()"
      ],
      "metadata": {
        "id": "CU2ZqZDgRcd9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Make some predicitions with our loaded model\n",
        "loaded_model_0.eval()\n",
        "with torch.inference_mode():\n",
        "  loaded_model_preds = loaded_model_0(X_test)\n",
        "\n",
        "loaded_model_preds"
      ],
      "metadata": {
        "id": "niQxjoxmRes9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Import Pytorch and matplotlip\n",
        "import torch\n",
        "from torch import nn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "torch.__version__"
      ],
      "metadata": {
        "id": "qF3e2V4qT2ut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Setup device agnostic code, use gpu if available else cpu\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "id": "457xKT_XlLEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.1 Data"
      ],
      "metadata": {
        "id": "xOqHsKKEmLNW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data using linear regression formula of y = weight * X + bias\n",
        "weight = 0.7\n",
        "bias = 0.3\n",
        "\n",
        "# Create range values\n",
        "start = 0\n",
        "end = 1\n",
        "step = 0.02\n",
        "\n",
        "# Create X and y  (features and labels)\n",
        "X = torch.arange(start, end, step).unsqueeze(dim=1)\n",
        "y = weight * X + bias\n",
        "X[:10], y[:10]"
      ],
      "metadata": {
        "id": "P59tszHbmrcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#split Data\n",
        "train_split = int(0.8 * len(X))\n",
        "X_train, y_train = X[:train_split], y[:train_split]\n",
        "X_test, y_test = X[train_split:], y[train_split:]\n",
        "len(X_train), len(y_train), len(X_test), len(y_test)"
      ],
      "metadata": {
        "id": "M2OTR2NLoj9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#building a pytorch model\n",
        "class LinearRegressionModelV2(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linear_layer  = nn.Linear(in_features=1,\n",
        "                                   out_features=1) # Changed out_features to 1\n",
        "\n",
        "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "    return self.linear_layer(x) # Apply the linear layer to the input x"
      ],
      "metadata": {
        "id": "RMrUGie5pJ74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1 = LinearRegressionModelV2()\n",
        "model_1.state_dict()"
      ],
      "metadata": {
        "id": "2GRvArMFtAOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the model current device\n",
        "next(model_1.parameters()).device"
      ],
      "metadata": {
        "id": "sfXTwNMKpUY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the model to use the target device\n",
        "model_1.to(device)\n",
        "next(model_1.parameters()).device"
      ],
      "metadata": {
        "id": "KS9t9YPstE1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.3 Training\n",
        "For training we need :\n",
        "* Loss function\n",
        "* Optimizer\n",
        "* Training Loop\n",
        "* Testing loop"
      ],
      "metadata": {
        "id": "0ImPAHnppjpu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup loss function\n",
        "loss_fn = nn.L1Loss() # same as MAE\n",
        "\n",
        "# Setup our optimizer\n",
        "optimizer = torch.optim.SGD(params=model_1.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "XpgeKbq6p569"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's write a training loop\n",
        "torch.manual_seed(42)\n",
        "\n",
        "epochs = 200\n",
        "\n",
        "#Put data on the target device\n",
        "X_train = X_train.to(device)\n",
        "y_train = y_train.to(device)\n",
        "X_test = X_test.to(device)\n",
        "y_test = y_test.to(device)\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  model_1.train()\n",
        "\n",
        "  # 1. Forward pass\n",
        "  y_pred = model_1(X_train)\n",
        "\n",
        "  # 2. Calculate the loss\n",
        "  loss = loss_fn(y_pred, y_train)\n",
        "\n",
        "  # 3. Optimizer zero grad\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  # 4. Perform backpropagation\n",
        "  loss.backward()\n",
        "\n",
        "  # 5. Optimizer step\n",
        "  optimizer.step()\n",
        "\n",
        "  ### Testing\n",
        "  model_1.eval()\n",
        "  with torch.inference_mode():\n",
        "    test_pred = model_1(X_test)\n",
        "\n",
        "    test_loss = loss_fn(test_pred, y_test)\n",
        "\n",
        "  # Print out whats happening\n",
        "  if epoch % 10 == 0:\n",
        "    print(f'Epoch : {epoch} | Loss {loss} | Test loss : {test_loss}')\n",
        "\n"
      ],
      "metadata": {
        "id": "7qyltvRlqSxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#turn model into evaluation mode\n",
        "model_1.eval()\n",
        "\n",
        "#Make predictions on the test data\n",
        "with torch.inference_mode():\n",
        "  y_pred = model_1(X_test)\n",
        "\n",
        "y_pred"
      ],
      "metadata": {
        "id": "aHZL49PlxLWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_predictions(predictions=y_pred.cpu())"
      ],
      "metadata": {
        "id": "auAxpgATxoyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving and loading a trained model\n",
        "from pathlib import Path\n",
        "\n",
        "# 1. Create models directory\n",
        "MODEL_PATH =  Path('models')\n",
        "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 2. Create model save path\n",
        "MODEL_NAME = '01_pytorch_workflow_model_1.pth'\n",
        "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
        "\n",
        "# 3. save the model state dict\n",
        "print(f'Saving model to: {MODEL_SAVE_PATH}')\n",
        "torch.save(obj=model_1.state_dict(), f=MODEL_SAVE_PATH)"
      ],
      "metadata": {
        "id": "nvxT82OAx_hf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.state_dict()"
      ],
      "metadata": {
        "id": "ThH1i_CJ0Jzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load a PyTorch\n",
        "\n",
        "#Create a new instance of linear regression model V2\n",
        "loaded_model_1 = LinearRegressionModelV2()\n",
        "\n",
        "#Load the saved model_1 state_dict\n"
      ],
      "metadata": {
        "id": "0h6xFU8Y0MNw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}